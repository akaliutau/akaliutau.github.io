<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://akaliutau.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://akaliutau.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-10T20:31:42+00:00</updated><id>https://akaliutau.github.io/feed.xml</id><title type="html">Aliaksei Kaliutau</title><subtitle>A personal website with blog and news. </subtitle><entry><title type="html">MVC 2024: highlights and impressions</title><link href="https://akaliutau.github.io/blog/2024/mvc-2024-highlights-and-impressions/" rel="alternate" type="text/html" title="MVC 2024: highlights and impressions"/><published>2024-06-23T21:01:59+00:00</published><updated>2024-06-23T21:01:59+00:00</updated><id>https://akaliutau.github.io/blog/2024/mvc-2024-highlights-and-impressions</id><content type="html" xml:base="https://akaliutau.github.io/blog/2024/mvc-2024-highlights-and-impressions/"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/512/1*ND6-WB-hGkSYboWImxNTEw.jpeg"/><figcaption>Coventry Building Society Arena, 18 June</figcaption></figure> <p>Last week, on June 18th, the UKIVA’s machine vision conference (MVC) event and tech show kicked off in Coventry. In 2024 it was co-located with another event — Automation UK. This is quite an interesting event, a wonderland of technology for everyone who is interested in robotics, machine vision and AI technologies. In my article I’m going to describe my impressions, new tech I saw and key trends I’ve had the pleasure to learn about. It was interesting, insightful and inspirational.</p> <h3>Why to attend</h3> <p>I usually do not have time to attend conferences; however, I find it beneficial to occasionally participate in meetups and tech events, particularly those within a commutable distance from London. For instance, in April 2024, I attended a meeting with leaders from Aerospike during their European tour, which focused on showcasing and promoting Real-Time Data technologies — though that’s a story for another time.</p> <p>Coventry definitely is not a place close to London, nevertheless I decided to visit MVC because of two reasons.</p> <p>First, the conference and its dedicated exhibition aimed to provide insights into “the very best of industrial vision and imaging,” and I was curious about what is considered the frontier technologies in this field. Second, I wanted to experience these technologies firsthand, to understand how they operate in the real world as opposed to just viewing pictures on a company’s website or videos on YouTube (which by the way not always possible because companies rarely publish too technical demos). This interest was both professional and personal, as my future research will involve AI, automation, and related fields.</p> <p>There was also one, less important reason — I wanted to know the format of UK conferences, so I expected an interesting experience.</p> <h3>Going to Coventry</h3> <p>The conference was held at the Coventry Building Society Arena, situated on the outskirts of the city. There is a direct train from London to Birmingham that stops at Coventry, making it easily accessible. The only potential challenge was the last hop of the journey, as the distance between the train station and the Building Society Arena is 5.5 km. It could be quite a long walk if you are a fan of walking, so it’s better to take a local bus.</p> <p>The day was windy and sunny, with an overcast afternoon, but this was not important at all, since the exhibition was entirely indoors. I arrived at 9 AM and received my badge. The first hour served as a warm-up and an opportunity to look around; all seminars commenced at 10 AM.</p> <p>When it comes to conferences, even attending them as a visitor or guest, it’s essential to plan ahead of time and decide which sessions to attend and what exactly you wish to learn during the available hours. This is crucial due to the sheer number of stands (for example this time it was 46 of them in total), and the inevitable overlap of seminars within the conference’s program: there were 33 seminars across three theaters. Even dedicating a mere 10 minutes per stand, exploring the entire exhibition would take over 7 hours.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/512/1*BUOAOOhuucjddOYXu5ktBw.jpeg"/><figcaption>The program of one of the theatre</figcaption></figure> <h3>The first look (and the first take)</h3> <p>My first stop at the conference was to visit several companies I had pre-selected the day before, focusing on specific technologies (I was primarily interested in AI-related tech and 3D scanners), so I took a quick look at their stands first. The companies were LMI Technologies and Lincode, and a couple of others. Overall, the event was a representative exhibition of machine vision technologies, emphasizing both components and complete solutions. Approximately 20–30% of all stands featured new hardware such as cameras, controllers, and specialized lighting equipment. This event struck me more as a technology fair with a sales aspect, rather than a showcase of new technologies.</p> <p><a href="https://lmi3d.com/company/">LMI Technologies</a> is a Canadian company specializing in 3D scanning and inspection. I was curious about their 3D cameras and “Embedded AI” technologies. <a href="https://lincode.ai/product.php">Lincode </a>on the other hand has not much to do with machine vision at all, this is more a (potentially successful) use-case of applied AI to solve the generic QA and visual inspection problem in various industries. Essentially, it’s a glimpse into that bright, fully automated future where factories operate without human intervention — welcome to Industry 4.0 in full spark! Lincode is among many US-based AI startups that have emerged in the Bay Area over the past five years, appearing and growing as mushrooms after the rain.</p> <p>As many companies showcased vision hardware, it was unsurprising to find the stands crowded with cameras, sensors, and the occasional robotic arm for solution demonstrations.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/512/1*k8-9fLqf1MFfhXuY0-v2vw.jpeg"/><figcaption>The industry’s most innovative and extensive product line</figcaption></figure> <h3>Seminars</h3> <p>It was fun to watch presentations and listen to presenters. The conference spanned two days, with reversed order of seminars on each, so in theory one could catch the missed sessions on the second day, but there were a lot of overlaps anyway. I’ve picked up <em>AI in Machine Vision: Cutting Through the Hype</em>, <em>A New Age of Deep Learning</em>, <em>AI Machine Vision advancements in manufacturing</em>, <em>Elevating AI with GMSL Cameras</em> and some others. The presentations were concise, lasting no more than 15 minutes each. I appreciated the clarity and brevity, because one could easily get the additional insights at appropriate stands anyway. It’s funny how much actually one can say in 10 mins, if to proper structure your speech!</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/512/1*19-OMEaEJVZd1SjZanOp6Q.jpeg"/><figcaption><em>AI in Machine Vision: Cutting Through the Hype</em></figcaption></figure> <h3>Post-event time and the host city</h3> <p>The MVC ’24 took place in Coventry, as well as it was in previous year. I expected Coventry to be a sleepy boring suburb town (partially it was), but the town center was surprisingly rich for historical buildings, artifacts and places to visit. In fact, the whole city center was a one giant cultural exposition with typical for the UK coexistence of millennia-old buildings with 21st-century architecture — a visual delight to explore before departure. Coventry Cathedral was one of the obvious sites worth visiting, but there were plenty of equally interesting small places which are normally not even mentioned in guides or somehow poorly visible or obscured on Google Maps.</p> <h3>Final thoughts</h3> <p>To summarize everything said above in one sentence, one might say in the following boring way: smart devices are becoming progressively more intelligent. “Edge AI” and “Deep Learning on Device” have become increasingly popular over the last 5–10 years, meaning ML revolution started spreading and invading the most fundamental levels of technology, down to the hardware itself. In fact, it started more than 20 years ago, and has exponentially accelerated in the 20s. It is evident that the technologies we now consider innovative and advanced, will soon be as commonplace and unremarkable as the face-tracking cameras on our smartphones. Plus manual labor in factories (any factories to be exact, in any industry) will become a thing of the past very soon.</p> <p>Perhaps the most valuable lessons I learned that day were the clear demonstrations of how to present new technology to an audience and how to effectively advertise products through live demos at exhibition stands. There’s a saying that it’s better to see something once than to read about it a hundred times, and I grabbed the opportunity for that and don’t regret it.</p> <p>In essence, the technology conference is not just a “knowledge-building moment” to learn something new, to catch up with latest trends and so on. It is a masterclass in communication, marketing, and the art of engagement. The technological progress, the future of technology is not just the creation of something and in pure innovation, but also in presentation and adoption of inventions. This worked for me, and hopefully the future will give me more learning opportunities like that.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/800/1*2K6kC-2XdX2RPfm6j2kjEw.jpeg"/></figure> <h3>References</h3> <p>[1] <a href="https://www.automation-uk.co.uk-">https://www.automation-uk.co.uk-</a> Automation UK (official website)<br/>[2] <a href="https://machinevisionconference.co.uk">https://machinevisionconference.co.uk</a> — MVC conference (official website) <br/>[3]<a href="https://www.instagram.com/akaliutau/">https://www.instagram.com/akaliutau/</a> — extra photos from event can be found on my IG</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fe49829b4e2f" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Software Engineering in 2025</title><link href="https://akaliutau.github.io/blog/2024/software-engineering-in-2025/" rel="alternate" type="text/html" title="Software Engineering in 2025"/><published>2024-04-12T18:15:33+00:00</published><updated>2024-04-12T18:15:33+00:00</updated><id>https://akaliutau.github.io/blog/2024/software-engineering-in-2025</id><content type="html" xml:base="https://akaliutau.github.io/blog/2024/software-engineering-in-2025/"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/512/1*tXXWzEjMnyfgJqe21WCpiQ.jpeg"/><figcaption>Tales for the accelerated time (generated with DALL-E 3)</figcaption></figure> <p>Long time ago, in another life, I found myself at a crossroads: whether to continue working in Data Science realm or to try something new. The year was 2015, and everything was different in that time, from the global economy to future prospects: literally every single venture promised infinite growth and opportunities, and I decided to seek new green pastures under the cloudless sky. Software development was a trendy activity in those days: industry showed no signs of slowing down, prospects seemed limitless, and since I already had about 5+ years of experience creating extremely complex and sophisticated software for data analytics, trying the role of a Software Engineer in real Software Development company was the next logical step, and I gave it a try.</p> <p>The transition was easy in some sense, because ML and signal analysis was the core of my multi-year project, and I could proudly call myself an expert in Python (and all ML stack): software which I created was like the technology from the future — some ideas were just well ahead their time.</p> <p>The transition was difficult because my first degree was in Physics, and my knowledge of the fundamentals of Computer Science and the principles of Software Engineering was like Swiss cheese — impressive expertise in some topics co-existed with knowledge gaps in others. For example, I could easily discuss the comparative advantages of Wavelet Transformations over Fourier analysis in image compression algorithms and time series data processing. Designing and training a neural network to extract insights from noisy data was a piece of cake for me; in Astronomy and High Energy Physics neural networks have been used to automatically analyze images and track elementary particles since at least 1994, become a de-facto standard in all elementary particle experiments and Big Science projects in the 21st century, and I had a lot of both hands-on experience and theoretical knowledge in this domain. But at the same time, I struggled to build even a simple website: plain HTML, the basics of JS, plus manual “fine-tuning” of CSS files was the pinnacle of my knowledge in web design — and this was in 2015, the age of Angular, React and CSS preprocessors! I had no idea how to deploy and scale out the backend, and I didn’t really know AWS or GCP (although I had some experience with Heroku — similar cloud service, and that experience along with many books about cloud technology helped me to gradually build up my very own understanding of cloud architecture and everything around it — check out my another article about how I got certified as a Google Cloud Architect in 2022).</p> <p>Another completely new experience was the realization that business objectives often take priority over accuracy and completeness in practical software engineering. By “practical”, I mean the real business that involves delivering solutions/software products to customers and users with an acceptable level of quality. When I worked on my own projects, I had more control and visibility over the trade-offs between quality and development speed; this visibility was almost nonexistent in the companies I worked for later. Deadlines were either implicit or not set at all, yet the business still expected the delivery of a sellable result within some (undisclosed) timeframe. At one point, I was on the verge of declaring a Brand New Approach/Framework to resolve such problematic ambiguity, only to discover later that it had already been invented in the form of the Agile framework.</p> <p>At work, I found out the ancient wisdom that Software Engineering is not all about <em>coding </em>(how many times has this sentence been pronounced on this planet?), but about <em>solving the problems</em>, and this in its turn may or may not include the actual coding. I found that sometimes it’s better to write a software which writes other software which solves the problem, rather than attacking the problem directly. For example, React is a perfect example of such software, which is effectively a code generator library which reduces the process of building of websites to adding up and bootstrapping the already existing components. Before 2015 it took me a week to create a simple website, in 2024 it takes me less than 1 min. In the last 10 years the approach to software creation has undergone a significant transformation, and today writing software is synonymous with either code generation or finding a generic solution that addresses an entire class of problems (which means writing a framework).</p> <p>All these observations have been gradually accumulating since 2015, and today, ten years later, I can compose a concise Software Engineering Manifesto (SWEM) on how to design and implement software systems in 2025 and beyond (including AI trends and its impact). This set of principles has helped me to exponentially accelerate my productivity — what others (including my past self) could build in one week, I can now accomplish in under two hours, which translates in 20x gain in productivity.</p> <p><strong>1. If you don’t know what to do — do nothing</strong></p> <p>Yes, in decision making the option “do nothing” has a right to exist. This is because there’s a chance that the existing solution (if there is one) is the best you can find in all universes; therefore, move on to the next problem. It could also be that it’s just too early to start working on the details, since there is no clarity on all the inputs and outputs, bolts and nuts. The “R” phase in R&amp;D can be exhausting and daunting, but this process should not be rushed — architectural or design mistakes are the hardest to fix.</p> <p><strong>2. Create once — use forever</strong></p> <p>In other words, do not start solving the problem from scratch each time. There are frameworks, libraries, and already existing end-to-end solutions that can be adapted for the new case with minimal, if any, changes. And only if the problem belongs to a brand-new class, start solving it from the first principles. Ideally the solution should be wrapped into a framework/library for this specific class of problems. This not only accelerates delivery — the created software also helps AI tools to easily learn patterns and generate the solution individually for each similar case (AI is not very good in writing low-level code, but just loves structure, repetition and clarity of software frameworks and the solutions built using those frameworks)</p> <p><strong>3. Automate anywhere</strong></p> <p>The smallest tasks eat 80% of time, and automation can make them obsolete, why not do that?</p> <p>The routine workday of Software Engineer is full of such tasks. Here are the most obvious examples:</p> <ul><li>Low-level quality checks (i.e. unit-tests) which free the whole team from the burden of double checking that everything is still working. Normally writing unit-tests is part of daily routine of developers, but this activity can be automated. For example, the code of unit-tests can be generated from high-level specs</li><li>Any DevOps and other *Ops can be automated <em>ad infinitum, </em>to the degree that all related roles could become obsolete</li><li>All technical bureaucracy, writing technical and non-technical documentation and other paperwork can be automated thanks to magic of LLMs</li></ul> <p><strong>4. Document everything</strong></p> <p>This includes bugs, releases, release digests, performance test reports, low-level designs, high-level designs, specs, API contracts, meeting minutes, brainstorm sessions — you will need these evidences to showcase your hard work and get promoted!</p> <p>On a more serious note, building (and maintaining) complex systems is all about consistency and order, which should help to stand against chaos and malevolent forces. This is true not only about software. Ancient Rome spanned across all of Europe and existed for millennia not because Romans were especially smart or skilled, but because they had Roman Law, plus highly trained and organized regular army, and the technology to build high-quality roads for excellent logistics.</p> <p>There is another, more subtle point here, which could become important in the future: documentation could be consumed by AI or used to write efficient prompts — in the future most complex systems will likely be designed by AI.</p> <p><strong>5. Optimize from day zero</strong></p> <p>Knuth would disagree, but he is not strictly speaking a Software Engineer — he is a Computer Scientist. These days companies do not have a luxury to refactor sub-optimal code, and in building scalable systems it’s crucial to write the optimal code from day 0, otherwise it’d be much cheaper for company to fire mediocre developers and instead them to hire those who can write proper software, than to pay millions of dollars in electricity bills and equipment cost to run inefficient software in production environment.</p> <p>A modern highly-scalable system is the mirror which reflects and magnifies your own flaws and foibles, and this is one of the reasons why FAANG companies which have to deal with such kind of systems use 5 stages of LeetCode-style interviews in order to find people who have decent coding skills, appropriate mindset and do not make mistakes (or at least do not make them more frequently than 1 out of 6)</p> <p><strong>6. Do it or Die</strong></p> <p>Otherwise what does the company pay you such a big salary for?</p> <p>But truth be told, this principle is primarily applicable to routine tasks. Any successfully completed task consists of much smaller, simpler tasks, and the big success starts with small, atomic achievements. Each task should be queued and completed on time, this maintains motivation and momentum, serves as a guide in hard times and during moments of self-doubt, and eventually helps to fulfill commitments.</p> <p><strong>7. This is a never ending journey</strong></p> <p>And that road is for you; keep going until the end.</p> <p>Perhaps this final principle should be the apotheosis of the entire manifesto. Every good Engineer has their own unstoppable engine inside, which motivates them to conquer new heights. This enigmatic engine is quintessentially a mystery, and I can say nothing about it; but you should trust yourself regarding what it’s whispering in your ear, and rationally reflect about your knowledge, strategic pathway and milestones, both past and future.</p> <p>Find the details about my career path here: <a href="https://www.linkedin.com/in/aliaksei-kaliutau/">https://www.linkedin.com/in/aliaksei-kaliutau/</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6b5a296ef6c9" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">How I studied English on Instagram</title><link href="https://akaliutau.github.io/blog/2024/how-i-studied-english-on-instagram/" rel="alternate" type="text/html" title="How I studied English on Instagram"/><published>2024-02-24T22:51:11+00:00</published><updated>2024-02-24T22:51:11+00:00</updated><id>https://akaliutau.github.io/blog/2024/how-i-studied-english-on-instagram</id><content type="html" xml:base="https://akaliutau.github.io/blog/2024/how-i-studied-english-on-instagram/"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/512/1*qAKJ85HKIR7CSWzcUr-uJw.jpeg"/><figcaption>Breaking the Glass Ceiling (generated with DALL-E 3)</figcaption></figure> <p>This article is to describe my journey to achieve the mastery in English. It was an extremely non-linear process, and this is one of the pieces which helped me to reach the goal.</p> <h3><strong>The Problem</strong></h3> <p>Studying foreign language is a meandrous, lengthy process, and the learning curve normally has a sigmoid shape. Usually it’s quite flat in the beginning, because you need to learn the basics, the building blocks and rules — without them you will speak a completely different language! This is followed by the phase of exponential expansion of the associative cloud of notions, concepts, idioms and of course words. After achieving an advanced level in English, the biggest obstacle to further progress is a problem of so-called creative writing, which requires not just good language skills, but also creativity, the ability to generate good ideas and put them to paper, which sometimes is difficult even if English is your native tongue.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1023/1*CBkCAVxQSFJwgDUU1foz0Q.png"/><figcaption>The learning curve</figcaption></figure> <p>After receiving my IELTS Academic C1 certificate, I started asking myself a question, why does the prose of my favorite writers — Robert Jordan and J.D. Salinger — look so good and sound almost like a song, while everything I am writing at best looks like the business letters from the bank — so bleak, clumsy and boring? In most cases the words were the same, but they missed their power, the magical ingredient which alchemically transforms “just words” into powerful, inspirational stories which are interesting to read.</p> <h3><strong>Enter Instagram</strong></h3> <p>One day, posting a picture on Instagram, I decided to add more text to the caption — more than usual hashtags and title (since IG allows you to attach up to 2200 characters to each picture anyway). The reason was simple — that text was supposed to be a memo, explaining why I took that picture and decided to store it at all. After that I thought: why not do this on a persistent basis? It could be fun and useful. In other words, I was about utilizing my IG account as an <em>illustrated blog</em>, rather than a <em>gallery</em>, to use it as a diary with glossy postcards, as a memory book keeping reminiscences about bright events, interesting artifacts, things which I liked, people that impressed me, achievements I was proud of. I have a photo archive close to 100GB of raw data, but starting forgetting when and why I did all these photos.</p> <p>Writing a good description for the picture/photo definitely requires some creative skills, even if you are just describing what is in the picture. The same picture can trigger a completely different sequence of thoughts in different people, so the description of what it means for <em>you </em>could come in handy. Describing your thoughts, your associations, what you are feeling — isn’t it exactly the prerequisite for creative writing? True: you have a topic — a picture, a task — to write 2200 characters of text, and the only thing you have to do is to start that journey, and then just go with a word flow.</p> <p>The text you are writing defines the title, and as a result thinking about what to write helps to give your post a good title, defining in that way much clearer what you actually want to remember when posting a picture. In addition, such types of exercises help to develop other relevant skills, such as observation, to expand your figurative language (metaphors, similes, etc.) And last but not least — this is normally a habitual, repetitive activity, and in learning foreign language consistency and persistence is the key to success and infinite growth.</p> <p>Of course, from the first glance using Instagram as a diary looks a bit absurd: who actually reads all these captions these days? People scroll the pictures and watch the reels! But from the other side, why should I care if creating a gallery was not the primary goal in the first place? Having these thoughts in my mind, I decided to try this experiment. Here we go!</p> <h3><strong>Results and analysis</strong></h3> <p>After around 100 posts I decided to estimate the volume of words I have written so far. In practicing English the rule “quality over quantity” does not necessarily work — during learning you have to train your brain to remember the spelling of all those words (unless you have the eidetic memory), so repetition does help a lot. And you don’t have to write a perfect post — this is just practice!</p> <p>Of course, the size of posts was different (and deviation was quite big), but on average I wrote 75 words, including hashtags and title, which gives us 75 X 100 = 7500 words.</p> <p>There are different systems for story classification by the word count, but here is a reasonable breakdown which I found in one article:</p> <p>Short Short Story (1,000 — 4,000)</p> <p>Long Short Story (4,000 — 7,500)</p> <p>Novelette (7,500 — 17,500 )</p> <p>Novella (17,500 — 40,000)</p> <p>Novel (40,000 and up)</p> <p>Which means that I have effectively written a short story already, in addition to other ways to study English! Since those writings are not really a kind of boring text of the letter from the bank, and they reflect what I was impressed by and interested in, this is almost a perfect implementation of creative writing setup, and I can work on polishing my English in a fun way. A simple projection says that after the counter on my IG has reached 534 posts, I will have a graphic novel distributed in Space-Time, a secret art project, a Bouts-Rimés poem made up from the sequence of pictures instead of a list of rhymed words, and after that I can officially call myself a writer. How cool is that?</p> <p>To summarize, in order to reach a really good level of English (or any other language), the most important thing is to use every opportunity to learn, and one can find these opportunities literally everywhere, the only thing you have to do is just to see them. Even such peculiar habits as writing descriptions to the pictures definitely helped me increase my vocabulary and develop the skills to write promptly something meaningful (or not so). Of course, it was not by any means the primary way for me to learn English — just a tiny part, a drop in an ocean, but as Ovid said “<em>Dripping water hollows out stone, not through force but through persistence</em>”</p> <h3><strong>References</strong></h3> <p>My IG: <a href="https://www.instagram.com/akaliutau/">https://www.instagram.com/akaliutau/</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0f666709cc4e" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">We, Robots</title><link href="https://akaliutau.github.io/blog/2022/we-robots/" rel="alternate" type="text/html" title="We, Robots"/><published>2022-12-30T02:33:49+00:00</published><updated>2022-12-30T02:33:49+00:00</updated><id>https://akaliutau.github.io/blog/2022/we-robots</id><content type="html" xml:base="https://akaliutau.github.io/blog/2022/we-robots/"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/400/1*HdKN-yYBAAyd0xEbLjMuyQ.jpeg"/></figure> <p>This article is about the revolution we have started, the evolution we are looking after, and the future we are making today.</p> <p>Every epoch, each society has its own bifurcation point — sometimes just a very specific time and place, sometimes spanning other decades — which redefines the life style, economical and societal fundamentals of one country, regions or even of the whole world. The XX century was surprisingly rich for such events. In 1920s one such event was the invention of conveyor and economy of mass production, in 1950s — it was nuclear energy and space technologies, in 1970s — microelectronics and biotechnology, and finally, on the edge of centuries — Internet, robotics and practical DNA constructing.</p> <p>Each wave dramatically changed the world, but despite differences, they all have something in common. This is a driving factor — the growth of humanity, both physical (the search for the fresh energy sources) and intellectual (hunger for the knowledge about world out there and beyond), but first and foremost — each wave was impossible without the previous one, preparing the platsdarm for the next jump.</p> <p>It’s unthinkable to understand DNA code without complex calculations, and those calculations are impossible without computers, hence the revolution in understanding of DNA code would not had started without invention of CPUs due to the very same reason as it’s impossible to build microprocessors using just screwdriver. So, even though all waves look different, they are actually parts of one giant game with unknown final goal hiding in the misty shadows of the future, the game with rules which are consonantly changing on each move.</p> <p>The next wave I can define as appearing and global spreading of self-sufficient, sustainable and intelligent technologies. By sustainable I mean here the technologies which can provide further growth of current civilization after logical burning of all oil and coal we have on Earth (the latter is necessary in order for the next two biggest countries in the world, China and India, to reach US/Western Europe’s level of HDI and to become advanced economies). Also those technologies can help to jump over the so-called <em>complexity barrier</em> in solving progressively sophisticated problems (complexity barrier is the situation, when at some point the problems are becoming so complex, that people are not even able to understand or solve them without some tools and base level of knowledge; the classic example is skyscraper technology, aka engineering of super-high rise buildings, which are simply impossible without invention of cranes, strong materials and advanced knowledge of static mechanics — the skyscraper cannot be built by stacking one brick on the top of another one without end, this is a construction of completely different engineering level).</p> <p>The growth without limits is not about transforming, exchanging one resource into another one (like tree into the book), it’s about using less resources to produce more, to achieve more, mocking the ecosystem on Earth, which managed to self-organize somehow to such degree that finally had allowed the descendants of eukaryotes from the ancient Ocean to read articles on Medium one billion years later)</p> <p>We cannot fork another biological evolution on Earth, and cannot construct DNA from scratch, but it’s feasible to fork a <em>technological </em>evolution, to design machines and give them the unpredictability and stubbornness of life, without falling into mechanical imitation of Nature, to start a separate branch of development and forever change the natural flow of history.</p> <p>There is one missing element of mosaic here, one can call it AI, or self-awareness, or independence, or something else. But whatever call it, it has to be the truly bifurcation point, with potential which can slowly unfold into infinity, with the promises higher than ever before.</p> <p>Unfortunately, the only clear thing here it seems this hypothetical bifurcation point is not going to be a point, but the whole epoch spanning over decades, maybe hundreds of years. Why is it so? Because in reality any evolution still has to comply some fundamental laws, and taking into account that the road from the first microorganisms on Earth till relativity theory was 3.42 billion years (roughly), the artificial techno evolution, even accelerated trillions of times, will require significant amount of time. If to think about transistors as analogs of cells in real nature, modern hardware is still on the level of viruses (at best).</p> <p>As for software, the most advanced types of artificial neural networks (DNN + CNN) are just nothing but optimization tools, which can find the sub-optimal or near-optimal solution to NP-hard problems (like Traveling Salesman Problem, Chess or Go), or generate the colorful pictures using hidden correlations in colors, styles and strokes in real paintings created by artists, or “write” the symphony using the same approach. But isn’t it just algorithm, the way to find correlations in data set or mold the solution into constraints rather than creating something original?</p> <p>Isaac Asimov in his sci-fi books greatly speculated about XXI century, but it seems he looked into the mirror, rather than into the future. He thought of robots as almost identical copies of humans, like human-like dolls, with character and personality, just made of different material. But as we know now, extrapolations normally do not work.</p> <p>The reality could look like another speculation about AI — hive mind, the awareness everywhere and nowhere, and this scenario tends to be more realistic.</p> <p>Imagine yourself over-increasing level of automation of everything which can only be automated, from automatic mines where robots and TBMs extract basic resources, till automated production lines and conveyors at factories producing millions and millions of item types, from pens and paper till cars and houses.</p> <p>Imagine yourself the automatic factories which produce other components which factories are built of, closing in such manner the production cycle.</p> <p>And finally, imagine yourself the control of all of this in the form of directives, commands, heuristics and strategies, so complex and interconnected, that in some moment it will become non-essential, who is actually the originator of some command — the Homo Sapience or some automated process? Of course, we are not going to outsource important decisions to machines, but if in the beginning this command would be like “turn off AC if there is too cold tomorrow in 8 AM”, but in 100 years from now it will (no doubts) become “think about how to improve the harvest of apples next year”, and this initiative will appear in the mind of machine.</p> <p>AI will become the smart environment, where the consciousness is so elusive as it is in real brain. And what has started from the dreams about smart home will become a smarter future.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3434804e280f" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Binary Strings and the Italian Spaghetti</title><link href="https://akaliutau.github.io/blog/2022/binary-strings-and-the-italian-spaghetti/" rel="alternate" type="text/html" title="Binary Strings and the Italian Spaghetti"/><published>2022-09-10T19:47:11+00:00</published><updated>2022-09-10T19:47:11+00:00</updated><id>https://akaliutau.github.io/blog/2022/binary-strings-and-the-italian-spaghetti</id><content type="html" xml:base="https://akaliutau.github.io/blog/2022/binary-strings-and-the-italian-spaghetti/"><![CDATA[<p>I am starting a series of technical essays with aim to describe advanced techniques/heuristics in algorithms’ design, and this article is going to be the opening one. This topic is often under-represented in textbooks and algorithm handbooks. Quite often you can find in there the final solution, but you get zero hints about <em>how</em> the author actually invented this algorithm. In addition, the logical, deductive way of explanations how the solution was found is more a wish of brain to stick labels and see direct road, rather than objective reflections about how all elements of puzzle were actually put together. The internal kitchen, the secret laboratory of those subtle thought processes — that is what we will be looking for.</p> <p>The technical complexity of problems which I picked up as examples is not very high, the full solution can be designed and coded in 10–15 minutes, and due to this very fact one can quite likely meet these (or similar) problems on interview at FAANG companies</p> <p>Let’s get started! Today we will take a look at <a href="https://leetcode.com/problems/time-needed-to-rearrange-a-binary-string/">one simple problem</a> tied with re-shuffling the parts of string.</p> <blockquote><em>You are given a binary string s. In one second, all occurrences of 01 are simultaneously replaced with 10. This process repeats until no occurrences of 01 exist.</em></blockquote> <blockquote><em>Return the number of seconds needed to complete this process.</em></blockquote> <p>And here is an example:</p> <p>t = 0 sec : 001011</p> <p>t = 1 sec : 010101</p> <p>t = 2 sec : 101010</p> <p>t = 3 sec : 110100</p> <p>t = 4 sec : 111000</p> <p>We are expecting to get 4 seconds as an answer</p> <p>This problem is from the class of “transformations of something (binary strings in our case) in accordance to some rules”. Usually we are asked about the number of steps to reach some specific state, or any other questions about the process and its result.</p> <p>This problem can be solved in many ways, but it’s a good idea to start from the most straightforward one — a brute force approach. To do that we have first of all to identify the action (transformation of string in our case) and then to build the <em>simulation of</em> this process. Working simulation is going to be a tool which gives us the answer to all our questions.</p> <p>For our case we have to code two methods — the first one to check that we indeed have reached the final state, and the second one — to implement transformation itself.</p> <p>The implementation of the first method is obvious — we have to iterate through all characters comparing two neighboring ones, looking for the pattern 01. If found, this means we do not have a solution yet, because it’s easy to see that the final string — the result of transformation steps — can only contain patterns 11, or 00, or 10 (true — if there is no 01 in string, it cannot be transformed anymore in accordance with described procedure, can it?).</p> <p>The transformation procedure itself is straightforward as well — on each step we have to make a copy of input string and generate a new one on its basis in accordance with rules defined in problem statement.</p> <p>Obviously we have to count the number of steps taken — because this is exactly what we are asked.</p> <p>What is the time and space complexity of this approach? Well, we are using a double buffer for initial string, so if the size of string is <em>n</em> characters, we will need an additional space of size <em>n</em>, hence the space complexity is <em>O(n)</em>. We can improve it to <em>O(1)</em>, but it’s out of scope of this article.</p> <p>As for the time complexity, we’re going through all characters in the given string on each iteration-transformation, and in worst case scenario we will need to perform <em>n</em> such iterations, so the answer is <em>O(n²)</em> which is not very fast.</p> <p>Now we have to take a short break, look around and answer one simple question:</p> <blockquote>why did we consider brute force approach at all if it’s so slow and inefficient?</blockquote> <p>The answer is — to create a correct solution which <em>works</em> and which gives us the correct answer to any input. As a result we can generate a <em>golden set of test cases</em> to validate the correctness of more sophisticated solutions, with more subtle and non-trivial logic. Sometimes (not always, but sometimes) to find a mathematical proof for correctness of some non-trivial algorithm could be more difficult than to solve the problem itself. The validation of such algorithm on input-output pairs from the generated golden set can be the easiest way to get some more or less solid evidences of correctness of this algorithm (this is also known as <em>empirical proof of algorithm</em> — in real world of advanced mathematics one can meet those proofs more often than you think)</p> <p>In order to demonstrate the logic and to visualize the step-by-step dynamic of transformations, I used a brute force approach to generate 20 steps of transformations for the following random string (it contains 20 ones and 17 zeros)</p> <p>1001111111110001011001110000000110101</p> <p>And here is a spaghetti-like visualization of these transformations. I marked with yellow color the paths of 1s on the their way to final position, so you can literally see the dynamics of their moves.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/779/1*tB8IukdMG6rsVXFy2cHm1w.png"/></figure> <p>It’s easy to see, that the answer to the question asked in this problem is the length of the rightmost path, which shows the trajectory of the rightmost 1.</p> <p>It’s obvious, that the shortest path should be a diagonal with length equals to the number of 0s to the left of the aforementioned rightmost 1.</p> <p>In this case we have a 17 such zeros, and the lower boundary for our answer is 17.</p> <p>But we can see that the actual length of path is <em>increased </em>due to some delays in moves of 1s (I marked these delays with red color). This is because one can move 1 to the left <strong>if and only if the left-side neighbor is 0</strong>. One can see that in case of contiguous sequence of 1s we have a blocker, or queue, which actually causes these delays.</p> <p>Also it’s easy to see that these queues are gradually disappearing on each transformation, and this disappearing is happening with speed modulated by the flow of 0s and 1s (the queue is growing when we meet 1s and shrinking otherwise)</p> <p>This gives us the hint how to build a super efficient algorithm to crack the problem.</p> <p>First, we will start from evaluation of the lower boundary for the answer, identifying the rightmost 1 and counting the number of 0s to the left of it.</p> <p>Next, iterating through all characters in string starting from the beginning till the last 1, we have to evaluate the possible delays in movement of 1s due to contiguous sequence of 1s. So each time we meet such continuous blocks we are increasing the excess delay, otherwise in case of 0s we are decreasing the excess. The answer to the question asked in problem will be our lower boundary <em>plus</em> the excess delay we’ve just calculated on the last step.</p> <p>What is the time and space complexity of this approach? Well, we are not using any buffers for initial string now, so the space complexity is <em>O(1)</em>, i.e. constant space.</p> <p>As for the time complexity, we have to iterate through all chars in string twice, so it’s going to be <em>O(2n)</em> which is close to theoretically best possible solution<em> O(n)</em>.</p> <p>And this is what we are eating today thinking about binary strings:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*su5LzyKAQDYOqi5lqDv3Ew.jpeg"/><figcaption>Pasta Puttanesca con aglio, olive e carpisti</figcaption></figure> <h3>References</h3> <p>[1] the source code of solutions —<a href="https://github.com/akaliutau/cs-problems-revisited/blob/fc23e08a8d2332d1bdaf7d861f4dc871246a713f/src/main/java/problem/advancedtopics/Solution357.java"> brute force</a> and <a href="https://github.com/akaliutau/cs-problems-revisited/blob/fc23e08a8d2332d1bdaf7d861f4dc871246a713f/src/main/java/problem/advancedtopics/Solution357opt.java">optimized</a></p> <p>[2] a recipe for todays dinner: <a href="https://www.simplyrecipes.com/recipes/pasta_puttanesca/">https://www.simplyrecipes.com/recipes/pasta_puttanesca/</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=293619b228d6" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">The Architect and the Helicopter Racing</title><link href="https://akaliutau.github.io/blog/2022/the-architect-and-the-helicopter-racing/" rel="alternate" type="text/html" title="The Architect and the Helicopter Racing"/><published>2022-07-10T14:51:21+00:00</published><updated>2022-07-10T14:51:21+00:00</updated><id>https://akaliutau.github.io/blog/2022/the-architect-and-the-helicopter-racing</id><content type="html" xml:base="https://akaliutau.github.io/blog/2022/the-architect-and-the-helicopter-racing/"><![CDATA[<p>This article is written on fresh impressions about passing the certification for the Google’s Professional Cloud Architect. It’s wrapped into structured report and spiced with good amount of thoughts, reminiscences about my similar experience with AWS Architect certification, and all of this is under the sauce of reflections about modern cloud technologies in general.</p> <p>I have successfully passed this exam in July 2022, and for me the whole journey was surprisingly refreshing and inspirational one. I’m going to dive deeper into the details in a moment.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/651/1*-8lESYkLDU9d6VaVYd4EqQ.png"/></figure> <h3>Why did I sit the exam?</h3> <p>Why, indeed? I’m a seasoned technologist with 5+ years experience in companies of various size. Jointly with my research work in the area of Computational Physics, CG and Fintech, it’s more than a decade in a business. Why should I sit at the school desk and jump through the hoops again?</p> <p>The answer is simple — for me the exam itself never was a prime target. I always thought about exams as <em>milestones</em>, showing me my progress, and serving at the same time the role of anchor, independent review of everything I know.</p> <p>Exam helps to avoid procrastinating indefinitely long time (we all just love doing this), via setting solid deadlines, helps to not get lost in self-illusions about how much you know, providing an objective evaluation of your design skills in building complex cloud systems.</p> <p>And the last, but not least , it helps to stay on right path and — the most importantly — to finish the marathon.</p> <h3>The Google way</h3> <p>Google always was an extraordinary company.</p> <p>In early days one could hear the weird questions in their interviews, like “Why are manhole covers round?”, or “How many gas stations/dogs/cats are there in the United States?”. These questions are not asked anymore, but the geekiness is not gone anywhere.</p> <p>This year they added an interesting case-study to their list of fictitious companies which are served as a background for the GPA exam’s questions. It’s a Helicopter Racing League, which according to description is “a global sports league for competitive helicopter racing”.</p> <p>The absurdity of such kind of sport is nicely married to the technical challenges faced in order to make the whole extravaganza highly entertaining and attractive. For example, how are you supposed to provide the live coverage? One will need a couple of air-crafts with cameras, because nobody will find entertaining to see only readings from GPS trackers on big tableau. Also it’s preferably to shoot everything in 4k (or even in 8k, because cameras can not be put too close to helicopters and people wish to see all in details, of course - especially the helicopter’s collisions which will take place for sure). Plus it’s nice to have a slow-motion mode due to high speed of helicopters (up to 250 mph, which is twice as more as the max speed of car bolides). So, how much data we will need to record and broadcast? A lot, I guess.</p> <p>I wonder, what they will come out with next time? Based on the history of Google’s peculiarities, it could be anything. Time will tell.</p> <h3>The importance of the planning</h3> <blockquote>Tactics win battles; strategy wins wars.</blockquote> <p>When it comes to anything related to informational technologies, the constant planning and preparations for the worst is the key which will allow you to succeed in everything. IT is a child of XX century, born in attempt to deal with exponentially growing amount of data, but only the XXI century has shown what this is about.</p> <p>The domain area of Google Cloud Architect exam is Cloud technologies, which is an enormously large topic nowadays, including both low-level concepts (such as networking and the building blocks of Internet) and the high-level ones, such as services, technologies and software frameworks.</p> <p>It took me a lot of time to structure my knowledge and work out the approach to solve design-specific questions. How much? It’s been about a year, which I spent on studying GCP documentation, reading books (check out my reviews in last section) and validating all what I have known via performing experiments in private space, to gain hands-on experience.</p> <p>This was a long road, but it helped me to master my skills, develop the cloud mindset and get confidence in my knowledge.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1013/1*IZIBBDsBLXfkm91O8b9p2g.png"/></figure> <h3>About exam</h3> <p>Skilled architect is not a juggler, who operates with fancy facts about which service/technology/approach can be used in a specific circumstances.</p> <p>He is not a coder either. This role is actually a quintessence of what the job of software developer is about in current world, which is — the job of helping people to handle big volume of information, to work more efficiently via automating and outsourcing routine work to computer systems, and to be more productive and creative via extending human abilities through ML/AI technologies. And to do all aforementioned <em>economically</em>, which is a synonym of a money-wise today.</p> <p>That’s why the exam contains quite a diverse set of questions.</p> <p>Roughly 30% of all questions are very technical ones, up to asking the exact syntax of command to perform some operation with cloud resources (this is to check the knowledge and hands-on experience with <em>gcloud</em>, <em>gsutil</em>, <em>bq </em>and other tools).</p> <p>Other questions implies the familiarity with system design. The correct answer to some questions may depend on details of company overview, business and technical requirements, and of the executive statement which you can find only in full description of use-case (but you don’t have to memorize the company’s profile — during exam you will have access to it)</p> <p>Be ready to expect some deep-level, non-trivial questions on Kubernetes (K8s) and DevOps stuff. Kubernetes is one of the corner-stone of Google Cloud (and to be fair, one of the foundation of any advanced distributed microservice based system). It’s a quite vast topic by itself, so I’d suggest to read a separate book devoted solely to K8s.</p> <p>Summarizing, in order to pass the GPA exam you have to have a wide and deep knowledge of everything related to GCP, both from practical and theoretical perspective. Which is, by the way, a sort of fair requirement — people holding architect roles have to know everything or nearly everything in many areas.</p> <h3>Final thoughts</h3> <p>In the final section I’d like to compare my experience of having GPA exam with taking a similar one for the knowledge of AWS platform (I’ve got certified as a AWS Architect in December of 2021)</p> <p>I have to say, the questions were not only quite similar to those from GCP, but in some cases there were direct relations. Which is kind of surprising, because Google Cloud and AWS are actually competitive offerings, and from the first sight they should use every single opportunity to advertise and show the advantages of their own solution over the one from the enemy house; but in reality Google actually <em>supports </em>integration with some AWS services via their newest technology called Anthos.</p> <p>Studying something, acquiring new knowledge is a very interesting process. I consider an absolute importance of finding what skills and hobbies fulfill your life, finding the way to extend your world-views, regain the childlike motivation to constantly widen your own circle of knowledge and expertise. Also it’s important to go out from time to time from your comfort zone, from convenient harbor of familiar and understandable, to escape from never-ending cycle of daily routine, job, schoolwork — you name it. It’s definitely not easy to just go out and do whatever you want to, due to lack of time or lack of motivation, due to responsibilities we all have and just physical limits of human beings, of human brain to consume new information. But this is absolutely necessary.</p> <p>Knowledge is power, it makes us who we are and what we are able to achieve, whom we will become, so accepting this life-path of Pioneer and Explorer of the Informational Frontier of strange new worlds is the mandatory prerequisite to your future success. Sadly, schooling and studying today are often tied with negative emotions, and the whole process of learning is not considered fascinating, but this is not how it is supposed to be. For me it seems like for many people the school (=learning) got associated with something strongly negative, which stresses out and eventually has become the symbol of dullness, boringness and uselessness.</p> <p>But it my mind studying got tied to the feeling of belonging to the club of like-minded people fell in love with intellectual search, competition and discovery.</p> <p>I acquire new knowledge in two main ways — via reading books (and passing relevant exams) and via work on different projects, both at work and in private space. The first way allows to gain theoretical knowledge in an acceptable tempo and volumes, giving you the control over the process.</p> <p>I consider work and personal projects to be a sort of trial which meant to show your mastery as it is seen from the objective point of view.</p> <p>For me the multi-year experience in various realms of technological universe was very precious exactly to its versatility. All this knowledge of different technologies, languages, frameworks, libraries, etc, etc, allows me today to see different approaches invisible to others, to create something that have never been done before, to innovate, to solve any problem in a creative way.</p> <p>I noticed that new knowledge is not a ballast but a Swiss-knife, a universal master key if you will, which is able to open the door of possibilities to the Unimaginable.</p> <h3>Useful references</h3> <p>[1] <a href="https://cloud.google.com/docs">https://cloud.google.com/docs</a> — the primary source of information about GCP and the bible containing the answers to literary any questions regarding platform. This is both an advantage and disadvantage in the same time. All topics are relatively good structured and categorized, but the amount of information could be overwhelming. So this can be viewed first of all as a <em>handbook</em>.</p> <p>[2] <em>Official Google Professional Cloud Architect Study Guide, </em>by Dan Sullivan<em> </em>— a very useful book, which brings insights on what type of questions you have to expect at Professional Cloud Architect exam. But it’s a quite high-level though. Ideally it should be the last book you have to read in your studying</p> <p>[3] <em>Professional Cloud Architect — Google Cloud Certification Guide,</em> by Konrad Clapa and Brian Gerrard — can be used (as the title suggests) as a guide. And yes, this is a detailed and thoughtfully methodological plan of studies. I’ve read this book in the very beginning of my journey, and it helped me a lot.</p> <p>[4] <em>Kubernetes in Action</em>, by Marko Luksa — a must read book on K8s and everything around</p> <p>[5] <a href="https://github.com/akaliutau/gcp-grimoire">https://github.com/akaliutau/gcp-grimoire</a> — these are the notes I used to prepare for the exam. This repository contains also some code and scripts I used to gain some hands-on experience with the platform. Practical part is quite skinny, because I already had an extensive experience with GCP. Note, there are official GCP repositories with how-to-do-it examples, and you should use those to close gaps in knowledge.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4fce12520715" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry></feed>